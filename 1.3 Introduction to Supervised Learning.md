# Course1: Guided Tour of Machine Learning in Finance
## Week3: Introduction to Neural Networks and TensorFlow

### 3.1 Dataflow Graph
Figuire 3.1:Dataflow Graph
![Dataflow Graph](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF21.png)
Tensor: Multidimentional Arrays. (mathematical objects)

Tensor + Dataflow = TensorFlow!

Figuire 3.2:Tensorflow: Lasy Evaluation
![Tensorflow:Lasy Evaluation](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF22.png)

Figuire 3.3:Reverse-Mode Autodiff
![Tensorflow:Reverse-Mode Autodiff](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF23.png)

### 3.2 A First Demo of TensorFlow
[See jupyter notebook09 in the book "hands on machine learning"](https://github.com/ageron/handson-ml/blob/master/09_up_and_running_with_tensorflow.ipynb)

Define a composite function:
![a composite function](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF24.png)

```python
def my_func(w,x):
  with tf.name_scope("f_0_level") as scope_0:
    f_0 = tf.exp(w[0,0]+w[0,1]*x)
  with tf.name_scope("f_1_level") as scope_1:
    f_1 = tf.exp(w[1,0]+w[1,1]*f_0)
  with tf.name_scope("f_2_level") as scope_2:
    f_2 = tf.exp(w[2,0]+w[2,1]*f1)
  
  return f2,f1,f0
```

python fucntion: stack(a,axis = 0 or 1 or 2 or... ) the number of choices of axis depends on the dimension of list a.

When axis = 0, take the first element of 'a' to be the first layer (element) of the new array. Take the second element of 'a' to be the second layer (element) of the new array. So on and so forth. (Can also be thought as via the x axis)

When axis = 1 (need 'a' to be at least two dimendional list), take the first element of every element of 'a' to be the first layer (element) of the new array.  Take the second element of every element of 'a' to be the second layer (element) of the new array.
So on and so forth. (Can also be thought as via the y axis)

When axis = 2 (need 'a' to be at least three dimendional list), take the first element of the first element of every element of 'a' to be the first layer (element) of the new array.  Take the second element of every element of 'a' to be the second layer (element) of the new array. (Can also be thought as via the z axis)

So on and so forth.

Intuitional examples:
![stack example1](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF26.png)
![stack example2](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF27.png)
Calculate the derivatives of f at w0:
![the derivatives of f at w0](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF25.png)

One mistake with the first line: af/aw0 = af/af2 * af2/aw20 = af2/aw20 = f2(w0) (Here 'a' means partial differentiation)

Other lines have the same problem.

Compute gradients using TensorFlow
![Compute gradients using TensorFlow part1](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF28.png)
![Compute gradients using TensorFlow part2](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF29.png)

[tensorflow_graph_in_jupyter](https://github.com/ageron/handson-ml/blob/master/tensorflow_graph_in_jupyter.py)


### 3.3 Linear Regression in TensorFlow

Artificial Neuron
![Compute gradients using TensorFlow part2](https://raw.githubusercontent.com/SuperSaiki/pics/master/MLinF30.png)
